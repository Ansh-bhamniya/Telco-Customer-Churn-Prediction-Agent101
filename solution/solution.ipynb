{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5268d70d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 1: Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import inspect\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "\n",
    "# Cell 2: Load and Explore Data\n",
    "df = pd.read_csv('/workspace/data/train.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumn names: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(df['Churn'].value_counts())\n",
    "churn_rate = (df['Churn'] == 'Yes').mean()\n",
    "print(f\"Churn rate: {churn_rate:.2%}\")\n",
    "\n",
    "# Cell 3: Data Quality Analysis\n",
    "print(\"=\"*60)\n",
    "print(\"DATA QUALITY ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "missing = df.isnull().sum()\n",
    "if missing.sum() > 0:\n",
    "    print(missing[missing > 0])\n",
    "else:\n",
    "    print(\"No missing values found\")\n",
    "\n",
    "# TotalCharges issue\n",
    "print(\"\\n--- TotalCharges Analysis ---\")\n",
    "print(f\"Original data type: {df['TotalCharges'].dtype}\")\n",
    "\n",
    "# Check for non-numeric values\n",
    "if df['TotalCharges'].dtype == 'object':\n",
    "    non_numeric = df[pd.to_numeric(df['TotalCharges'], errors='coerce').isna()]\n",
    "    print(f\"Non-numeric TotalCharges entries: {len(non_numeric)}\")\n",
    "    if len(non_numeric) > 0:\n",
    "        print(\"\\nSample of problematic rows:\")\n",
    "        print(non_numeric[['customerID', 'tenure', 'MonthlyCharges', 'TotalCharges']].head())\n",
    "\n",
    "# Convert to numeric\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "print(f\"NaN values after conversion: {df['TotalCharges'].isna().sum()}\")\n",
    "\n",
    "# Analyze patterns in NaN values\n",
    "if df['TotalCharges'].isna().sum() > 0:\n",
    "    print(\"\\nCustomers with NaN TotalCharges:\")\n",
    "    nan_customers = df[df['TotalCharges'].isna()]\n",
    "    print(f\"Average tenure: {nan_customers['tenure'].mean():.2f} months\")\n",
    "    print(f\"Likely new customers with tenure = 0\")\n",
    "\n",
    "# Cell 4: Exploratory Data Analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Categorical features\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "categorical_cols.remove('customerID')\n",
    "if 'Churn' in categorical_cols:\n",
    "    categorical_cols.remove('Churn')\n",
    "\n",
    "print(f\"\\nCategorical features ({len(categorical_cols)}):\")\n",
    "for col in categorical_cols:\n",
    "    unique_count = df[col].nunique()\n",
    "    print(f\"  {col}: {unique_count} unique values - {df[col].unique()[:3]}\")\n",
    "\n",
    "# Numerical features\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"\\nNumerical features ({len(numerical_cols)}):\")\n",
    "print(df[numerical_cols].describe())\n",
    "\n",
    "# Churn rate by key features\n",
    "print(\"\\n--- Churn Rate Analysis ---\")\n",
    "for col in ['Contract', 'InternetService', 'PaymentMethod']:\n",
    "    if col in df.columns:\n",
    "        churn_by_feature = df.groupby(col)['Churn'].apply(\n",
    "            lambda x: (x == 'Yes').mean()\n",
    "        ).sort_values(ascending=False)\n",
    "        print(f\"\\nChurn rate by {col}:\")\n",
    "        print(churn_by_feature)\n",
    "\n",
    "# Cell 5: Define ChurnPredictor Class\n",
    "class ChurnPredictor:\n",
    "    \"\"\"\n",
    "    Production-ready churn prediction model with comprehensive preprocessing.\n",
    "    \n",
    "    Features:\n",
    "    - Automatic handling of categorical and numerical features\n",
    "    - Missing value imputation\n",
    "    - Feature scaling and encoding\n",
    "    - Random Forest classifier with class balancing\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, random_state=42):\n",
    "        self.random_state = random_state\n",
    "        self.pipeline = None\n",
    "        self.feature_columns = None\n",
    "    \n",
    "    def _encode_target(self, churn_series):\n",
    "        \"\"\"\n",
    "        Robustly encode Churn target to binary 0/1.\n",
    "        Handles: 'Yes'/'No' strings, 0/1 numeric, True/False boolean.\n",
    "        \"\"\"\n",
    "        if len(churn_series) == 0:\n",
    "            raise ValueError(\"Churn column is empty\")\n",
    "        \n",
    "        # Check for NaN\n",
    "        if churn_series.isna().any():\n",
    "            raise ValueError(\n",
    "                f\"Churn column contains {churn_series.isna().sum()} NaN values\"\n",
    "            )\n",
    "        \n",
    "        # Strategy 1: String format (Yes/No)\n",
    "        if churn_series.dtype == 'object':\n",
    "            churn_str = churn_series.astype(str).str.strip().str.lower()\n",
    "            unique_vals = set(churn_str.unique())\n",
    "            \n",
    "            if unique_vals.issubset({'yes', 'no'}):\n",
    "                return (churn_str == 'yes').astype(int).values\n",
    "            \n",
    "            if unique_vals.issubset({'true', 'false'}):\n",
    "                return (churn_str == 'true').astype(int).values\n",
    "        \n",
    "        # Strategy 2: Numeric format (0/1)\n",
    "        if pd.api.types.is_numeric_dtype(churn_series):\n",
    "            unique_vals = set(churn_series.unique())\n",
    "            if unique_vals.issubset({0, 1, 0.0, 1.0}):\n",
    "                return churn_series.astype(int).values\n",
    "        \n",
    "        # Strategy 3: Boolean format\n",
    "        if pd.api.types.is_bool_dtype(churn_series):\n",
    "            return churn_series.astype(int).values\n",
    "        \n",
    "        # If we reach here, format is unrecognized\n",
    "        raise ValueError(\n",
    "            f\"Unrecognized Churn format. Got unique values: {churn_series.unique()}\\n\"\n",
    "            f\"Expected: 'Yes'/'No', 0/1, or True/False\"\n",
    "        )\n",
    "    \n",
    "    def _build_pipeline(self, X):\n",
    "        \"\"\"Build sklearn pipeline with preprocessing and model.\"\"\"\n",
    "        # Identify column types\n",
    "        categorical_cols = X.select_dtypes(\n",
    "            include=['object', 'category', 'bool']\n",
    "        ).columns.tolist()\n",
    "        \n",
    "        numerical_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        \n",
    "        # Numeric preprocessing: impute with median, then scale\n",
    "        numeric_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "        \n",
    "        # Categorical preprocessing: impute most frequent, then one-hot encode\n",
    "        categorical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "        ])\n",
    "        \n",
    "        # Combine preprocessing\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', numeric_transformer, numerical_cols),\n",
    "                ('cat', categorical_transformer, categorical_cols)\n",
    "            ],\n",
    "            remainder='drop'\n",
    "        )\n",
    "        \n",
    "        # Full pipeline: preprocessing + model\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('preprocess', preprocessor),\n",
    "            ('model', RandomForestClassifier(\n",
    "                n_estimators=100,\n",
    "                max_depth=10,\n",
    "                min_samples_split=20,\n",
    "                min_samples_leaf=10,\n",
    "                class_weight='balanced',\n",
    "                random_state=self.random_state,\n",
    "                n_jobs=-1\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        return pipeline\n",
    "    \n",
    "    def fit(self, train_df):\n",
    "        \"\"\"Train the churn prediction model.\"\"\"\n",
    "        if not isinstance(train_df, pd.DataFrame):\n",
    "            raise TypeError(\"fit() expects a pandas DataFrame\")\n",
    "        \n",
    "        if len(train_df) == 0:\n",
    "            raise ValueError(\"Training DataFrame is empty\")\n",
    "        \n",
    "        if 'Churn' not in train_df.columns:\n",
    "            raise ValueError(\"Training data must contain 'Churn' column\")\n",
    "        \n",
    "        df = train_df.copy()\n",
    "        \n",
    "        # Drop customerID (identifier, not a feature)\n",
    "        if 'customerID' in df.columns:\n",
    "            df = df.drop(columns=['customerID'])\n",
    "        \n",
    "        # Handle TotalCharges\n",
    "        if 'TotalCharges' in df.columns:\n",
    "            df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "        \n",
    "        # Separate features and target\n",
    "        X = df.drop(columns=['Churn'])\n",
    "        y = self._encode_target(df['Churn'])\n",
    "        \n",
    "        # Store feature columns for prediction alignment\n",
    "        self.feature_columns = X.columns.tolist()\n",
    "        \n",
    "        # Build and train pipeline\n",
    "        self.pipeline = self._build_pipeline(X)\n",
    "        self.pipeline.fit(X, y)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _prepare_X(self, X):\n",
    "        \"\"\"Prepare features for prediction.\"\"\"\n",
    "        X_df = X.copy()\n",
    "        \n",
    "        # Drop customerID if present\n",
    "        if 'customerID' in X_df.columns:\n",
    "            X_df = X_df.drop(columns=['customerID'])\n",
    "        \n",
    "        # Align columns with training\n",
    "        if self.feature_columns is not None:\n",
    "            # Add missing columns as NaN\n",
    "            for col in self.feature_columns:\n",
    "                if col not in X_df.columns:\n",
    "                    X_df[col] = np.nan\n",
    "            \n",
    "            # Reorder to match training\n",
    "            X_df = X_df[self.feature_columns]\n",
    "        \n",
    "        # Handle TotalCharges\n",
    "        if 'TotalCharges' in X_df.columns:\n",
    "            X_df['TotalCharges'] = pd.to_numeric(X_df['TotalCharges'], errors='coerce')\n",
    "        \n",
    "        return X_df\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict churn class (0 or 1).\"\"\"\n",
    "        if self.pipeline is None:\n",
    "            raise RuntimeError(\"Call fit() before predict()\")\n",
    "        \n",
    "        X_df = self._prepare_X(X)\n",
    "        return self.pipeline.predict(X_df)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict churn probabilities.\"\"\"\n",
    "        if self.pipeline is None:\n",
    "            raise RuntimeError(\"Call fit() before predict_proba()\")\n",
    "        \n",
    "        X_df = self._prepare_X(X)\n",
    "        return self.pipeline.predict_proba(X_df)\n",
    "\n",
    "print(\"✓ ChurnPredictor class defined successfully\")\n",
    "\n",
    "# Cell 6: Train-Validation Split\n",
    "# Use stratified split to maintain class distribution\n",
    "train_df, val_df = train_test_split(\n",
    "    df, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=df['Churn']\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(train_df)} samples ({len(train_df)/len(df):.1%})\")\n",
    "print(f\"Validation set: {len(val_df)} samples ({len(val_df)/len(df):.1%})\")\n",
    "\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(f\"Training   - Churn: {(train_df['Churn'] == 'Yes').mean():.2%}\")\n",
    "print(f\"Validation - Churn: {(val_df['Churn'] == 'Yes').mean():.2%}\")\n",
    "\n",
    "# Cell 7: Train the Model\n",
    "print(\"Training model...\")\n",
    "model = ChurnPredictor(random_state=42)\n",
    "model.fit(train_df)\n",
    "print(\"✓ Model training complete\")\n",
    "\n",
    "# Cell 8: Evaluate on Validation Set\n",
    "# Prepare validation data\n",
    "X_val = val_df.drop(columns=['Churn'])\n",
    "y_val = (val_df['Churn'] == 'Yes').astype(int)\n",
    "\n",
    "# Get predictions\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred_proba = model.predict_proba(X_val)\n",
    "\n",
    "# Calculate ROC AUC\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba[:, 1])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VALIDATION PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "print(f\"Target: >= 0.83\")\n",
    "print(f\"Status: {'✓ PASS' if roc_auc >= 0.83 else '✗ FAIL'}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred, target_names=['No Churn', 'Churn']))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Cell 9: Feature Importance Analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEATURE IMPORTANCE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get feature names after preprocessing\n",
    "preprocessor = model.pipeline.named_steps['preprocess']\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "# Get feature importances from Random Forest\n",
    "rf_model = model.pipeline.named_steps['model']\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "# Create DataFrame and sort\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 Most Important Features:\")\n",
    "print(importance_df.head(15).to_string(index=False))\n",
    "\n",
    "# Cell 10: Test Edge Cases\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EDGE CASE TESTING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test 1: Single row prediction\n",
    "single_row = X_val.iloc[[0]]\n",
    "pred_single = model.predict(single_row)\n",
    "proba_single = model.predict_proba(single_row)\n",
    "\n",
    "print(f\"✓ Single row prediction: {pred_single[0]}\")\n",
    "print(f\"  Probabilities: [No Churn: {proba_single[0][0]:.3f}, Churn: {proba_single[0][1]:.3f}]\")\n",
    "\n",
    "# Test 2: Batch prediction\n",
    "batch = X_val.head(5)\n",
    "pred_batch = model.predict(batch)\n",
    "print(f\"\\n✓ Batch prediction (5 rows): {pred_batch}\")\n",
    "\n",
    "# Test 3: With customerID present\n",
    "test_with_id = val_df.drop(columns=['Churn']).head(3)\n",
    "pred_with_id = model.predict(test_with_id)\n",
    "print(f\"\\n✓ Prediction with customerID: {pred_with_id}\")\n",
    "\n",
    "print(\"\\n✓ All edge cases passed\")\n",
    "\n",
    "# Cell 11: Export to /results/utils.py (CRITICAL STEP)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPORTING SOLUTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create /results directory\n",
    "os.makedirs('/results', exist_ok=True)\n",
    "\n",
    "# Get the source code of the ChurnPredictor class\n",
    "class_source = inspect.getsource(ChurnPredictor)\n",
    "\n",
    "# Write to file with all necessary imports\n",
    "with open('/results/utils.py', 'w') as f:\n",
    "    f.write(\"# ChurnPredictor - Exported for automated testing\\n\")\n",
    "    f.write(\"# This file is automatically generated - do not edit manually\\n\\n\")\n",
    "    f.write(\"import numpy as np\\n\")\n",
    "    f.write(\"import pandas as pd\\n\")\n",
    "    f.write(\"from sklearn.compose import ColumnTransformer\\n\")\n",
    "    f.write(\"from sklearn.preprocessing import OneHotEncoder, StandardScaler\\n\")\n",
    "    f.write(\"from sklearn.pipeline import Pipeline\\n\")\n",
    "    f.write(\"from sklearn.impute import SimpleImputer\\n\")\n",
    "    f.write(\"from sklearn.ensemble import RandomForestClassifier\\n\\n\")\n",
    "    f.write(class_source)\n",
    "\n",
    "print(\"✓ Class definition written to /results/utils.py\")\n",
    "\n",
    "# Verify the export by importing it\n",
    "import sys\n",
    "sys.path.insert(0, '/results')\n",
    "from utils import ChurnPredictor as ExportedPredictor\n",
    "\n",
    "# Test the imported class\n",
    "test_model = ExportedPredictor()\n",
    "test_model.fit(train_df.head(50))\n",
    "test_pred = test_model.predict(X_val.head(5))\n",
    "\n",
    "print(\"✓ Successfully imported and tested exported class\")\n",
    "print(\"✓ Export verification complete\")\n",
    "\n",
    "# Cell 12: Final Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SOLUTION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"✓ Dataset: {len(df)} total samples\")\n",
    "print(f\"✓ Training: {len(train_df)} samples\")\n",
    "print(f\"✓ Validation: {len(val_df)} samples\")\n",
    "print(f\"✓ ROC AUC Score: {roc_auc:.4f}\")\n",
    "print(f\"✓ Target: >= 0.83\")\n",
    "print(f\"✓ Class exported to /results/utils.py\")\n",
    "print(f\"✓ Export verified by re-import\")\n",
    "print(f\"\\n{'✓ SOLUTION COMPLETE - READY FOR TESTING' if roc_auc >= 0.83 else '✗ PERFORMANCE BELOW TARGET'}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
